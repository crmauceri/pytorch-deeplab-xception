{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import scipy.io as sio\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from dataloaders import make_data_loader\n",
    "from deeplab3.config.defaults import get_cfg_defaults\n",
    "from deeplab3.test import Tester\n",
    "\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_configs = model_utils.get_all_models(\"../run/cityscapes/\")\n",
    "len(model_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgb_xception_scenenet/2020_09_25-22_05_32/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgb_xception_scenenet/2020_09_25-22_05_32/parameters.yaml\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgb_xception_scenenet/2020_09_25-22_04_04/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgb_xception_scenenet/2020_09_25-22_04_04/parameters.yaml\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgb_xception_scenenet/2020_09_25-22_08_16/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgb_xception_scenenet/2020_09_25-22_08_16/parameters.yaml\n",
      "Non-existent key: DATASET.CITYSCAPES.TEST_SET\n",
      "Non-existent key: DATASET.CITYSCAPES.TEST_SET\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_hha_midfusion/2020_09_29-03_21_42/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_hha_midfusion/2020_09_29-03_21_42/parameters.yaml\n",
      "Using RGB input\n",
      "Found 19997 train_extra images\n",
      "Using RGB input\n",
      "Found 500 val images\n",
      "Using RGB input\n",
      "Found 1525 test images\n",
      "Loading pretrained Xception model: http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      ":   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint '../run/cityscapes/cityscapes_rgb_xception_low_light_pt/2020_09_29-15_58_37/checkpoint.pth.tar' (epoch 1)\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loss: 1.597: 100%|██████████| 125/125 [03:19<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgb_xception_pt/2020_09_29-15_55_19/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgb_xception_pt/2020_09_29-15_55_19/parameters.yaml\n",
      "Using RGB-D input\n",
      "Found 19997 train_extra images\n",
      "Using RGB-D input\n",
      "Found 500 val images\n",
      "Using RGB-D input\n",
      "Found 1525 test images\n",
      "Training backbone from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      ":   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint '../run/cityscapes/cityscapes_rgbd_xception_low_light/2020_09_25-19_32_43/checkpoint.pth.tar' (epoch 44)\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loss: 0.090: 100%|██████████| 125/125 [04:24<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-existent key: DATASET.CITYSCAPES.TEST_SET\n",
      "while scanning for the next token\n",
      "found character '\\t' that cannot start any token\n",
      "  in \"../run/cityscapes/cityscapes_rgbd_resnet_coco_fine/2020_08_05-18_17_41/parameters.yaml\", line 34, column 3\n",
      "../run/cityscapes/cityscapes_rgbd_resnet_coco_fine/2020_08_05-18_17_41/parameters.yaml\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgb_xception_low_light/2020_09_25-19_36_29/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgb_xception_low_light/2020_09_25-19_36_29/parameters.yaml\n",
      "Using RGB input\n",
      "Found 19997 train_extra images\n",
      "Using RGB input\n",
      "Found 500 val images\n",
      "Using RGB input\n",
      "Found 1525 test images\n",
      "Training backbone from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      ":   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint '../run/cityscapes/cityscapes_rgb_xception_low_light/2020_09_25-19_36_53/checkpoint.pth.tar' (epoch 59)\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loss: 0.110: 100%|██████████| 125/125 [03:19<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_05_38/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_05_38/parameters.yaml\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_03_19/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_03_19/parameters.yaml\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_05_52/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_05_52/parameters.yaml\n",
      "[Errno 2] No such file or directory: '../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_07_20/checkpoint.pth.tar'\n",
      "../run/cityscapes/cityscapes_rgbd_xception_scenenet/2020_09_25-22_07_20/parameters.yaml\n"
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "model_output = {}\n",
    "\n",
    "for cfg_filepath in model_configs:\n",
    "    try:\n",
    "        cfg = model_utils.match_cfg_versions(cfg_filepath)\n",
    "        cfg.merge_from_list(['CHECKPOINT.DIRECTORY', os.path.dirname(cfg_filepath),\n",
    "                             'TEST.MAX_ITER', 1000,\n",
    "                            'MODEL.PRETRAINED', \"\",\n",
    "                            'SYSTEM.GPU_IDS', [0]]) #Since we're using saved models, pretrained weights will be overwritten anyway.\n",
    "\n",
    "        model_filepath = os.path.join(cfg.CHECKPOINT.DIRECTORY, cfg.CHECKPOINT.MODEL)\n",
    "        checkpoint = torch.load(model_filepath, map_location=torch.device('cpu'))\n",
    "        \n",
    "        model_output[cfg_filepath] = {'dataset': cfg.DATASET.NAME,\n",
    "                                         'model': cfg.MODEL.NAME,\n",
    "                                         'image_type': cfg.DATASET.MODE,\n",
    "                                         'low_light': str(cfg.DATASET.DARKEN.DARKEN),\n",
    "                                         'epoch': checkpoint['epoch']}\n",
    "        \n",
    "        result_file = os.path.join(cfg.CHECKPOINT.DIRECTORY, 'validation_report.txt')\n",
    "        checkpoint_file = os.path.join(cfg.CHECKPOINT.DIRECTORY, 'checkpoint.pth.tar')\n",
    "        if os.path.exists(result_file) and (datetime.datetime.fromtimestamp(os.path.getmtime(result_file)) > datetime.datetime(2020, 10, 15)): #os.path.getmtime(checkpoint_file)):\n",
    "            with open(result_file, 'r') as fp:\n",
    "                metric_str = fp.read().split('{')[1].split('}')[0].replace(\"'\", '\"')\n",
    "                metrics = json.loads('{' + metric_str + '}')\n",
    "        else:\n",
    "            #failed.append(cfg_filepath)\n",
    "            metrics = model_utils.test_model(cfg, result_file, cfg.CHECKPOINT.DIRECTORY + '/confusion.mat')\n",
    "\n",
    "        model_output[cfg_filepath].update(metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(cfg_filepath)\n",
    "        failed.append(cfg_filepath)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(failed))\n",
    "model_configs = failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def plot_comparison(dataset='cityscapes', low_light='False'):\n",
    "    best = defaultdict(lambda: defaultdict(dict))\n",
    "    for key, value in model_output.items():\n",
    "        if value['low_light']==low_light:\n",
    "            model = \"/\".join(key.split('/')[3:5])\n",
    "            model = '{}({})'.format(model, value['epoch'])\n",
    "            if model in best[value['dataset']][value['image_type']]:\n",
    "                compare_to = best[value['dataset']][value['image_type']][model]\n",
    "\n",
    "                if value['mIoU'] > compare_to:\n",
    "                    compare_to = value['mIoU']\n",
    "            else:\n",
    "                best[value['dataset']][value['image_type']][model] = value['mIoU']\n",
    "\n",
    "    df = pd.DataFrame(best[dataset])\n",
    "    column_names = df.columns.values.tolist()\n",
    "    column_names.sort()  # Make sure all the colors are in the same order \n",
    "    df = df.sort_values(column_names)\n",
    "\n",
    "    color=['red', 'green', 'blue']\n",
    "    color_dict = dict(zip(column_names, color[:len(column_names)]))\n",
    "    ax = df.plot(kind='barh', figsize=(12,8), color=color_dict)\n",
    "    for p in ax.patches:\n",
    "        if p.get_width() > 0 :\n",
    "            ax.annotate(\"{:2.2}\".format(p.get_width()), (p.get_width() * 1.005, p.get_y() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(low_light='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(dataset='scenenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(dataset='scenenet', low_light='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(dataset='coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(dataset='coco', low_light='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
